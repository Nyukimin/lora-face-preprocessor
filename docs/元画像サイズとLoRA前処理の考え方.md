# 元画像サイズとLoRA前処理の考え方

## このドキュメントの目的
LoRA学習において「画像サイズを揃えるべきか」という問題は、
技術的ではなく思想の問題である。

本ドキュメントでは、
なぜ必ずしもサイズ統一を行わないのかを説明する。

---

## 重要な前提
LoRAはピクセルを直接学習しているわけではない。

- 画像は latent 空間に変換される
- 学習されるのは特徴の分布
- サイズより「情報密度」が重要

---

## なぜ小さい画像を無理に拡大しないのか

### アップスケールは情報を増やさない
小さな画像を1024に拡大しても、

- 新しい情報は生まれない
- 補間による推測が混ざる

これはLoRAにとって「偽の特徴」になる。

---

### 特に顔LoRAでは致命的
顔LoRA（identity LoRA）では以下が重要。

- 目の形
- まぶたの角度
- 口角の癖
- 鼻先の形状

ここにボケや補完ノイズが混ざると、
生成結果の安定性が著しく低下する。

---

## サイズ不揃いは問題ではない
kohya-ss / SDXL の学習パイプラインでは、

- 画像サイズが混在しても問題ない
- 内部で正規化される

問題になるのは以下。

- 歪んだ顔
- 嘘のディテール
- 意図しない補完

サイズそのものではない。

---

## 推奨ポリシー（顔LoRA）

| 項目 | 推奨 |
|---|---|
| 最大サイズ | 1024 |
| 小画像の扱い | 拡大しない |
| サイズ統一 | しない |
| 情報密度 | 重視 |
| 安定性 | 最優先 |

---

## 実装指針としての考え方
サイズを揃えないのは「手抜き」ではない。

- 情報を壊さない
- 嘘を教えない
- 足りないものは足さない

これはLoRA前処理として、安全側の設計である。

---

## 補足
雰囲気LoRAや大規模datasetでは、
この方針を緩める余地がある。

用途ごとに前処理思想を分けることが重要。
